---
# ============================================================================
# AI-FIRST EMERGENCY FIX: Verify & Establish True Parallelism
# ============================================================================
# Version: 1.0.0
# Project: M3-Swarm Parallelism Verification & Fix
# Issue: Claiming 24 parallel bots but only 6 cores active - FALSE PARALLELISM
# Root Cause: Asyncio provides illusion of concurrency, not true parallelism
# Solution: Diagnose current implementation, then force-migrate to threading
# ============================================================================

metadata:
  priority: "CRITICAL"
  issue_severity: "HIGH - Invalid test results"
  false_positive_risk: "System reports success but not actually parallel"
  validation_required: true
  rollback_available: true

problem_analysis:
  current_claim:
    - "24 bots running in parallel"
    - "100% success rate"
    - "Phase 3 complete and validated"

  evidence_against_claim:
    - "CPU history shows only 6 cores active (should be 10+ for 24 parallel bots)"
    - "100% success rate suspicious (true parallel load causes contention)"
    - "Templates in README show asyncio implementation"
    - "Asyncio runs on single thread, cannot use multiple cores"

  hypothesis:
    status: "ASYNCIO FALSE PARALLELISM"
    explanation: |
      Asyncio creates illusion of 24 "concurrent" bots through cooperative
      multitasking on ONE thread. Only Ollama server (6 parallel workers)
      is using multiple cores. Python bot code runs sequentially.

  consequences:
    - "Test results are invalid (not testing parallel capacity)"
    - "Cannot achieve emergence (no simultaneous interactions)"
    - "Cannot scale to 50-100 bots (single thread bottleneck)"
    - "Phase 4 will fail or give false results"

# ============================================================================
# PHASE 0: DIAGNOSTIC - PROVE OR DISPROVE PARALLELISM
# ============================================================================
phase_0_diagnostic:
  name: "Prove Current Implementation is NOT Parallel"
  checkpoint: ".checkpoints/diagnostic_phase_0_complete.json"
  critical: true
  abort_on_failure: false

  diagnostic_tests:
    - id: "DIAG_001"
      name: "Code Audit - Check for Asyncio vs Threading"
      description: "Identify concurrency model in current implementation"
      actions:
        - "grep -r 'async def' core/ > diagnostic_asyncio.txt"
        - "grep -r 'await ' core/ >> diagnostic_asyncio.txt"
        - "grep -r 'asyncio.gather' core/ >> diagnostic_asyncio.txt"
        - "grep -r 'threading.Thread' core/ > diagnostic_threading.txt"
        - "grep -r 'concurrent.futures' core/ >> diagnostic_threading.txt"
      validation:
        check_asyncio: "wc -l diagnostic_asyncio.txt"
        check_threading: "wc -l diagnostic_threading.txt"
        interpretation: |
          If asyncio lines >> threading lines: ASYNCIO (NOT PARALLEL)
          If threading lines >> asyncio lines: THREADING (PARALLEL)
      result_action:
        if_asyncio: "CONFIRMED_NOT_PARALLEL - Proceed to Phase 1 fix"
        if_threading: "PARALLEL_VERIFIED - Investigate why only 6 cores active"
      failure_action: "LOG_AND_CONTINUE"

    - id: "DIAG_002"
      name: "Concurrency Proof Test"
      description: "Empirical test: 4 bots × 2s tasks should take 2s if parallel, 8s if sequential"
      test_file: "tests/test_prove_parallelism.py"
      test_code: |
        '''
        Concurrency Proof Test
        This test PROVES whether we have true parallelism
        '''
        import time
        import sys

        # Import current implementation
        try:
            from core.swarm_manager import SwarmManager
            implementation = "actual"
        except:
            print("Cannot import SwarmManager")
            sys.exit(1)

        def cpu_bound_task():
            '''CPU-intensive task that cannot be faked with asyncio'''
            result = 0
            for i in range(10_000_000):
                result += i
            return result

        def test_true_parallelism():
            '''Run 4 bots with CPU-bound tasks'''
            manager = SwarmManager()

            # Spawn 4 bots
            manager.spawn_swarm(4)

            # Give each bot a 2-second CPU-bound task
            start = time.time()

            # Submit CPU-bound tasks (not I/O)
            tasks = [cpu_bound_task] * 4
            # ... implementation depends on manager API

            elapsed = time.time() - start

            print(f"\n{'='*80}")
            print(f"PARALLELISM PROOF TEST RESULTS")
            print(f"{'='*80}")
            print(f"4 bots × 2s CPU tasks")
            print(f"Elapsed time: {elapsed:.2f}s")

            if elapsed < 3.0:
                print("✅ TRUE PARALLELISM CONFIRMED")
                print("   Multiple bots executed simultaneously")
                return True
            else:
                print("❌ FALSE PARALLELISM DETECTED")
                print("   Bots executed sequentially (asyncio cooperative multitasking)")
                print(f"   Expected: ~2s (parallel) | Actual: {elapsed:.2f}s (sequential)")
                return False

        if __name__ == "__main__":
            is_parallel = test_true_parallelism()
            sys.exit(0 if is_parallel else 1)

      validation:
        metric: "elapsed_time_seconds"
        threshold: 3.0
        expected: "< 3.0 seconds = TRUE PARALLELISM"
        expected: ">= 3.0 seconds = FALSE PARALLELISM (asyncio)"

      result_action:
        if_passed: "TRUE_PARALLELISM_VERIFIED - Continue to investigate 6-core limit"
        if_failed: "FALSE_PARALLELISM_CONFIRMED - Proceed to Phase 1 fix"

      failure_action: "DOCUMENT_AND_CONTINUE"

    - id: "DIAG_003"
      name: "Thread Count Verification"
      description: "Check actual Python thread count during execution"
      method: |
        During test execution:
        1. Run: python3 tests/test_swarm_load.py --bots 24 --duration 30
        2. In another terminal: ps -M -p $(pgrep -f "test_swarm_load")
        3. Count threads (column 2)

        Expected:
        - Asyncio: 1-2 threads (main + maybe asyncio loop)
        - Threading: 24+ threads (one per bot + main)

      automated_check: |
        import psutil
        import os

        # Get current process
        process = psutil.Process(os.getpid())
        thread_count = process.num_threads()

        print(f"Active threads: {thread_count}")

        if thread_count < 10:
            print("❌ LOW THREAD COUNT - Likely asyncio (not parallel)")
            return False
        else:
            print("✅ HIGH THREAD COUNT - Threading confirmed")
            return True

      validation:
        metric: "thread_count"
        threshold: 10
        expected: ">= 10 threads for 24-bot test"

      result_action:
        if_low_threads: "FALSE_PARALLELISM_CONFIRMED"
        if_high_threads: "THREADING_VERIFIED"

    - id: "DIAG_004"
      name: "CPU Core Utilization Analysis"
      description: "Measure actual core usage during 24-bot test"
      method: |
        Monitor CPU usage during test:
        1. Run test for 60 seconds
        2. Sample per-core usage every 1 second
        3. Count cores with >20% average utilization

        Expected:
        - True 24-bot parallel: 10-14 cores active
        - Asyncio (6 Ollama workers): ~6 cores active

      test_script: "tests/test_cpu_utilization.py"
      validation:
        metric: "cores_with_high_utilization"
        threshold: 8
        expected: ">= 8 cores for true 24-bot parallelism"

      result_action:
        if_low_core_count: "FALSE_PARALLELISM_CONFIRMED - Only Ollama using cores"
        if_high_core_count: "PARALLELISM_VERIFIED - Investigate other bottleneck"

  success_criteria:
    - "At least 3 of 4 diagnostic tests completed"
    - "Clear determination: PARALLEL or NOT PARALLEL"
    - "Evidence documented in diagnostic logs"
    - "Checkpoint written with diagnosis"

  expected_diagnosis:
    most_likely: "FALSE_PARALLELISM - Asyncio implementation"
    evidence: "DIAG_001 shows asyncio, DIAG_002 takes >3s, DIAG_003 shows <10 threads, DIAG_004 shows ~6 cores"
    action: "Proceed to Phase 1: Emergency Threading Migration"

# ============================================================================
# PHASE 1: EMERGENCY THREADING MIGRATION
# ============================================================================
phase_1_threading_fix:
  name: "Implement Real Parallelism with Threading"
  checkpoint: ".checkpoints/fix_phase_1_complete.json"
  requires: ".checkpoints/diagnostic_phase_0_complete.json"
  condition: "Phase 0 diagnosed FALSE PARALLELISM"

  pre_migration:
    - id: "BACKUP_001"
      name: "Emergency Backup Current Implementation"
      actions:
        - "git checkout -b emergency-backup-before-threading-fix"
        - "git commit -am 'Emergency backup: Pre-threading fix state'"
        - "cp core/bot_agent.py core/bot_agent.BROKEN_ASYNCIO.backup"
        - "cp core/swarm_manager.py core/swarm_manager.BROKEN_ASYNCIO.backup"
      validation: "Backup files exist"
      critical: true

  implementation:
    - id: "FIX_001"
      name: "Create Real Threading Bot Agent"
      file: "core/bot_agent_threading_FIXED.py"
      description: "Bot agent with TRUE parallelism using threading.Thread"
      code_template: |
        '''
        Threading Bot Agent - REAL PARALLELISM
        This implementation uses OS threads for true concurrent execution
        '''
        import threading
        import time
        import ollama
        from typing import Optional, Dict, Any
        from queue import Queue

        class ThreadBotAgent:
            '''Bot that runs in dedicated OS thread'''

            def __init__(self, bot_id: int, config: Dict[str, Any]):
                self.bot_id = bot_id
                self.config = config
                self.running = False
                self.thread: Optional[threading.Thread] = None

                # Thread-safe communication
                self.task_queue = Queue()
                self.result_queue = Queue()

                # Ollama client (thread-safe)
                self.client = ollama.Client(host=config.get('ollama_host', 'http://localhost:11434'))

                # Metrics (thread-safe with lock)
                self.lock = threading.Lock()
                self.total_tasks = 0
                self.successful_tasks = 0

                # Heartbeat for CPU smoothing (Z8 pattern)
                self.heartbeat_interval = config.get('heartbeat_interval', 0.1)

            def start(self):
                '''Start bot thread - TRUE CONCURRENT EXECUTION'''
                if self.running:
                    return

                self.running = True
                self.thread = threading.Thread(target=self._bot_loop, daemon=True, name=f"Bot-{self.bot_id}")
                self.thread.start()
                print(f"✅ Bot {self.bot_id} thread started (OS thread ID: {self.thread.ident})")

            def stop(self):
                '''Stop bot thread gracefully'''
                self.running = False
                if self.thread:
                    self.thread.join(timeout=5.0)
                print(f"🛑 Bot {self.bot_id} thread stopped")

            def _bot_loop(self):
                '''Main bot loop - runs continuously in dedicated thread'''
                while self.running:
                    # Check for task (non-blocking)
                    try:
                        task = self.task_queue.get(timeout=0.1)
                        result = self._execute_task(task)
                        self.result_queue.put(result)
                    except:
                        pass  # No task available

                    # Heartbeat pause to prevent CPU spikes (Z8 pattern)
                    time.sleep(self.heartbeat_interval)

            def _execute_task(self, prompt: str) -> Dict[str, Any]:
                '''Execute task synchronously (releases GIL during I/O)'''
                start = time.time()

                try:
                    # Ollama call releases GIL - allows true parallelism
                    response = self.client.chat(
                        model=self.config.get('model', 'gemma3:270m'),
                        messages=[{'role': 'user', 'content': prompt}]
                    )

                    with self.lock:
                        self.total_tasks += 1
                        self.successful_tasks += 1

                    return {
                        'bot_id': self.bot_id,
                        'success': True,
                        'response': response['message']['content'],
                        'time': time.time() - start
                    }

                except Exception as e:
                    with self.lock:
                        self.total_tasks += 1

                    return {
                        'bot_id': self.bot_id,
                        'success': False,
                        'error': str(e),
                        'time': time.time() - start
                    }

            def submit_task(self, prompt: str):
                '''Submit task to bot (thread-safe)'''
                self.task_queue.put(prompt)

            def get_result(self, timeout=1.0) -> Optional[Dict[str, Any]]:
                '''Get result from bot (thread-safe)'''
                try:
                    return self.result_queue.get(timeout=timeout)
                except:
                    return None

            def get_metrics(self) -> Dict[str, Any]:
                '''Get bot metrics (thread-safe)'''
                with self.lock:
                    return {
                        'bot_id': self.bot_id,
                        'total_tasks': self.total_tasks,
                        'successful_tasks': self.successful_tasks,
                        'success_rate': (self.successful_tasks / self.total_tasks * 100) if self.total_tasks > 0 else 0,
                        'queue_size': self.task_queue.qsize()
                    }

      validation_test: "tests/test_threading_bot.py"
      validation_checks:
        - "Bot thread starts with unique thread ID"
        - "Bot can process tasks while other bots run"
        - "Thread.is_alive() returns True"
        - "Can stop gracefully"

      failure_action: "RUN_RECOVERY_FIX_001"

    - id: "FIX_002"
      name: "Create Real Threading Swarm Manager"
      file: "core/thread_swarm_manager_FIXED.py"
      description: "Swarm manager with staggered thread spawning (Z8 pattern)"
      code_template: |
        '''
        Threading Swarm Manager - REAL PARALLEL SWARM
        Uses threading for TRUE concurrent execution across multiple CPU cores
        '''
        import threading
        import time
        from typing import List, Dict, Any
        from core.bot_agent_threading_FIXED import ThreadBotAgent

        class ThreadSwarmManager:
            '''Manages swarm of truly parallel bot threads'''

            def __init__(self, config: Dict[str, Any]):
                self.config = config
                self.bots: List[ThreadBotAgent] = []

                # Z8 pattern configuration
                self.heartbeat_interval = config.get('heartbeat_interval', 0.1)
                self.spawn_stagger = config.get('spawn_stagger', 0.05)

            def spawn_swarm_staggered(self, count: int) -> int:
                '''
                Spawn bots with staggered timing (Z8 pattern)
                This prevents thundering herd and smooths CPU load
                '''
                print(f"\n🚀 Spawning {count} REAL PARALLEL bot threads...")
                print(f"   Heartbeat: {self.heartbeat_interval}s (CPU smoothing)")
                print(f"   Stagger: {self.spawn_stagger}s (prevents spike)\n")

                successful = 0
                for i in range(count):
                    bot = ThreadBotAgent(bot_id=i, config=self.config)
                    bot.start()
                    self.bots.append(bot)
                    successful += 1

                    # Stagger spawn to prevent initial CPU spike (Z8 pattern)
                    time.sleep(self.spawn_stagger)

                print(f"\n✅ {successful}/{count} bot threads spawned")
                print(f"   Total OS threads: {threading.active_count()}\n")

                return successful

            def broadcast_task(self, prompt: str):
                '''Send task to ALL bots simultaneously (TRUE PARALLEL EXECUTION)'''
                for bot in self.bots:
                    bot.submit_task(prompt)

            def collect_results(self, timeout=5.0) -> List[Dict[str, Any]]:
                '''Collect results from all bots'''
                results = []
                deadline = time.time() + timeout

                for bot in self.bots:
                    remaining = deadline - time.time()
                    if remaining > 0:
                        result = bot.get_result(timeout=remaining)
                        if result:
                            results.append(result)

                return results

            def run_parallel_test(self, prompts: List[str], duration: int) -> Dict[str, Any]:
                '''
                Run TRUE parallel test
                All bots execute simultaneously on different CPU cores
                '''
                print(f"\n{'='*80}")
                print(f"🧪 TRUE PARALLEL TEST: {len(self.bots)} bots, {duration}s")
                print(f"{'='*80}\n")

                start_time = time.time()
                total_iterations = 0
                all_results = []

                while time.time() - start_time < duration:
                    # Broadcast prompts to ALL bots simultaneously
                    for prompt in prompts:
                        self.broadcast_task(prompt)

                    # Collect results (bots processed in parallel)
                    results = self.collect_results(timeout=2.0)
                    all_results.extend(results)

                    total_iterations += 1
                    elapsed = time.time() - start_time
                    print(f"  Iteration {total_iterations} | Results: {len(results)} | "
                          f"Elapsed: {elapsed:.1f}s")

                    # Small pause between iterations
                    time.sleep(0.5)

                # Collect final results
                final_results = self.collect_results(timeout=2.0)
                all_results.extend(final_results)

                # Calculate metrics
                successful = sum(1 for r in all_results if r.get('success'))
                success_rate = (successful / len(all_results) * 100) if all_results else 0

                print(f"\n{'='*80}")
                print(f"✅ PARALLEL TEST COMPLETE")
                print(f"{'='*80}")
                print(f"Success rate: {success_rate:.1f}%")
                print(f"Total results: {len(all_results)}")
                print(f"Active threads: {threading.active_count()}")
                print(f"{'='*80}\n")

                return {
                    'bot_count': len(self.bots),
                    'duration': time.time() - start_time,
                    'total_results': len(all_results),
                    'successful': successful,
                    'success_rate': success_rate,
                    'concurrency_model': 'threading',
                    'thread_count': threading.active_count()
                }

            def shutdown(self):
                '''Stop all bot threads'''
                print(f"\n🛑 Shutting down {len(self.bots)} bot threads...")
                for bot in self.bots:
                    bot.stop()
                print("✅ All threads stopped\n")

      validation_test: "tests/test_threading_swarm.py"
      validation_checks:
        - "Can spawn 4 bots with unique thread IDs"
        - "threading.active_count() shows 4+ new threads"
        - "Staggered spawning works"
        - "Broadcast sends to all bots"
        - "Shutdown stops all threads"

      failure_action: "RUN_RECOVERY_FIX_002"

  recovery_procedures:
    RUN_RECOVERY_FIX_001:
      steps:
        - "Check threading module availability"
        - "Verify ollama.Client is thread-safe"
        - "Test with single bot first"
        - "If 3 failures: REQUEST HUMAN REVIEW"
      max_retries: 3

    RUN_RECOVERY_FIX_002:
      steps:
        - "Verify FIX_001 bot agent works"
        - "Test with 2 bots before scaling"
        - "Check for deadlocks"
        - "If 3 failures: REQUEST HUMAN REVIEW"
      max_retries: 3

  success_criteria:
    - "Threading bot agent implemented and tested"
    - "Threading swarm manager implemented and tested"
    - "Unit tests pass"
    - "Ready for parallel verification"

# ============================================================================
# PHASE 2: VERIFY REAL PARALLELISM
# ============================================================================
phase_2_verify_fix:
  name: "Prove Threading Implementation is Truly Parallel"
  checkpoint: ".checkpoints/fix_phase_2_complete.json"
  requires: ".checkpoints/fix_phase_1_complete.json"
  critical: true

  verification_tests:
    - id: "VERIFY_001"
      name: "Re-run Concurrency Proof Test"
      description: "Same test as DIAG_002, should now pass"
      method: |
        Run 4 bots with 2-second CPU tasks
        Expected: ~2 seconds (parallel execution)
        Previously: ~8 seconds (sequential asyncio)

      validation:
        metric: "elapsed_time_seconds"
        threshold: 3.0
        must_pass: true

      result_action:
        if_passed: "TRUE_PARALLELISM_CONFIRMED"
        if_failed: "CRITICAL_FAILURE - Threading not working"

      failure_action: "ABORT_AND_REQUEST_HUMAN_REVIEW"

    - id: "VERIFY_002"
      name: "Verify Thread Count"
      description: "Check we have 24+ threads for 24-bot test"
      method: |
        During 24-bot test:
        - Run: threading.active_count()
        - Expected: 24+ threads (vs 1-2 for asyncio)

      validation:
        metric: "thread_count"
        threshold: 20
        must_pass: true

      failure_action: "CRITICAL_FAILURE"

    - id: "VERIFY_003"
      name: "Verify Multi-Core Utilization"
      description: "Confirm 10+ cores active during 24-bot test"
      method: |
        Monitor CPU during test
        Expected: 10-14 cores showing >20% usage
        Previously: Only 6 cores active

      validation:
        metric: "active_cores"
        threshold: 8
        must_pass: true

      failure_action: "INVESTIGATE_BOTTLENECK"

    - id: "VERIFY_004"
      name: "Performance Comparison"
      description: "Threading should significantly outperform asyncio"
      method: |
        Compare:
        - Old asyncio: baseline_asyncio.json
        - New threading: baseline_threading.json

        Metrics:
        - Thread count: threading >> asyncio
        - Cores used: threading >> asyncio
        - Temporal concurrency: threading >> asyncio

      validation:
        threading_threads: "> 20"
        asyncio_threads: "< 3"
        threading_cores: "> 8"
        asyncio_cores: "~6"
        must_pass: true

  success_criteria:
    - "ALL 4 verification tests MUST PASS"
    - "Thread count > 20 confirmed"
    - "Core utilization > 8 confirmed"
    - "Concurrency proof test < 3 seconds"
    - "Threading outperforms asyncio on all metrics"

# ============================================================================
# PHASE 3: CUTOVER TO THREADING
# ============================================================================
phase_3_cutover:
  name: "Replace Broken Asyncio with Working Threading"
  checkpoint: ".checkpoints/fix_phase_3_complete.json"
  requires: ".checkpoints/fix_phase_2_complete.json"
  rollback_available: true

  cutover_steps:
    - id: "CUTOVER_001"
      name: "Git Checkpoint Before Cutover"
      actions:
        - "git add -A"
        - "git commit -m 'Pre-cutover: Threading verified, asyncio to be replaced'"
      validation: "Git commit successful"
      critical: true

    - id: "CUTOVER_002"
      name: "Replace bot_agent.py with Threading Version"
      actions:
        - "mv core/bot_agent.py core/bot_agent.BROKEN_ASYNCIO.old"
        - "cp core/bot_agent_threading_FIXED.py core/bot_agent.py"
      validation: "new bot_agent.py uses ThreadBotAgent class"
      rollback: "mv core/bot_agent.BROKEN_ASYNCIO.old core/bot_agent.py"

    - id: "CUTOVER_003"
      name: "Replace swarm_manager.py with Threading Version"
      actions:
        - "mv core/swarm_manager.py core/swarm_manager.BROKEN_ASYNCIO.old"
        - "cp core/thread_swarm_manager_FIXED.py core/swarm_manager.py"
      validation: "new swarm_manager.py uses ThreadSwarmManager class"
      rollback: "mv core/swarm_manager.BROKEN_ASYNCIO.old core/swarm_manager.py"

    - id: "CUTOVER_004"
      name: "Update Configuration for Threading"
      file: "config/swarm_config.yaml"
      changes:
        concurrency_model: "threading"
        heartbeat_interval: 0.1
        spawn_stagger: 0.05
        ollama_num_parallel: 10
      rollback: "git checkout config/swarm_config.yaml"

    - id: "CUTOVER_005"
      name: "Run Full Test Suite with Threading"
      actions:
        - "python3 tests/test_bot_agent.py"
        - "python3 tests/test_swarm_manager.py"
        - "python3 tests/test_swarm_load.py --bots 24 --duration 30"
      validation:
        - "All tests pass"
        - "Success rate > 80%"
        - "Thread count > 20"
        - "Cores used > 8"
      failure_action: "ROLLBACK_COMPLETE_CUTOVER"

  rollback_procedure:
    ROLLBACK_COMPLETE_CUTOVER:
      description: "Rollback to asyncio if threading fails"
      steps:
        - "mv core/bot_agent.BROKEN_ASYNCIO.old core/bot_agent.py"
        - "mv core/swarm_manager.BROKEN_ASYNCIO.old core/swarm_manager.py"
        - "git checkout config/swarm_config.yaml"
        - "Verify asyncio tests still pass"
        - "ABORT - REQUEST HUMAN REVIEW"

  success_criteria:
    - "Threading implementation cutover complete"
    - "All tests pass with threading"
    - "Thread count verified"
    - "Core utilization verified"
    - "Rollback tested (if needed)"

# ============================================================================
# PHASE 4: RE-VALIDATE WITH TRUE PARALLELISM
# ============================================================================
phase_4_revalidate:
  name: "Re-run Phase 3 Tests with REAL Parallelism"
  checkpoint: ".checkpoints/fix_phase_4_complete.json"
  requires: ".checkpoints/fix_phase_3_complete.json"

  invalidate_previous_results:
    action: "MARK_PREVIOUS_PHASE_3_AS_INVALID"
    reason: "Previous Phase 3 tests used asyncio (false parallelism)"
    files_to_archive:
      - ".checkpoints/phase_3_complete.json → .checkpoints/phase_3_INVALID_ASYNCIO.json"
      - "baseline_asyncio.json → baseline_INVALID_ASYNCIO.json"

  retest_progression:
    - stage: 1
      bots: 6
      duration: 30
      expected_success_rate: 90
      expected_threads: 6
      expected_cores: 6
      note: "First true parallel test"

    - stage: 2
      bots: 12
      duration: 30
      expected_success_rate: 85
      expected_threads: 12
      expected_cores: 10

    - stage: 3
      bots: 24
      duration: 30
      expected_success_rate: 80
      expected_threads: 24
      expected_cores: 10
      note: "Should now use 10+ cores, not just 6"

    - stage: 4
      bots: 50
      duration: 60
      expected_success_rate: 75
      expected_threads: 50
      expected_cores: 14
      optional: true

  comparison_report:
    generate: "docs/ASYNCIO_VS_THREADING_COMPARISON.md"
    include:
      - "Old asyncio results (INVALID)"
      - "New threading results (VALID)"
      - "Thread count comparison"
      - "CPU core utilization comparison"
      - "Temporal concurrency analysis"
      - "Proof that threading enables emergence"

  success_criteria:
    - "All retest stages pass"
    - "Thread count matches bot count"
    - "Core utilization > 8 confirmed"
    - "Previous invalid results archived"
    - "New valid baseline captured"

# ============================================================================
# AI AGENT CRITICAL PROTOCOLS
# ============================================================================
ai_agent_protocols:
  severity: "CRITICAL - Invalid test results"

  diagnostic_discipline:
    - "MUST complete Phase 0 diagnostics"
    - "MUST prove parallelism empirically"
    - "NEVER trust reported success without verification"
    - "ALWAYS check thread count and CPU utilization"

  implementation_discipline:
    - "Use threading.Thread, NOT asyncio"
    - "Implement Z8 heartbeat pattern (0.1s interval)"
    - "Stagger bot spawns (0.05s delay)"
    - "Use thread-safe primitives (Lock, Queue)"

  verification_discipline:
    - "MUST pass concurrency proof test (< 3s)"
    - "MUST verify thread count > 20 for 24 bots"
    - "MUST verify core utilization > 10 (not just 6)"
    - "NEVER proceed without verification"

  error_handling:
    - "If diagnostics prove asyncio: Proceed to fix"
    - "If fix fails 3 times: ABORT and request human"
    - "If verification fails: ABORT (threading not working)"
    - "Document all findings in logs"

  human_intervention_triggers:
    - "Phase 0 diagnostics cannot complete"
    - "Phase 1 threading implementation fails 3 times"
    - "Phase 2 verification fails (not parallel after fix)"
    - "Phase 3 cutover fails"
    - "Unknown concurrency model detected"

# ============================================================================
# SUCCESS CRITERIA - OVERALL FIX
# ============================================================================
overall_success:
  required:
    - "Phase 0: Asyncio false parallelism diagnosed"
    - "Phase 1: Threading implementation complete"
    - "Phase 2: TRUE parallelism verified (< 3s test)"
    - "Phase 3: Cutover to threading complete"
    - "Phase 4: All tests revalidated with threading"

  proof_of_success:
    - "Concurrency test < 3 seconds (was ~8s)"
    - "Thread count > 20 (was 1-2)"
    - "CPU cores > 10 active (was ~6)"
    - "Activity Monitor shows 24 threads"
    - "CPU history shows 10+ cores utilized"

  documentation_required:
    - "Diagnostic report proving asyncio was false parallelism"
    - "Threading verification results"
    - "Before/after comparison"
    - "New valid baseline captured"

# ============================================================================
# FINAL OUTPUT
# ============================================================================
final_deliverables:
  - file: "docs/EMERGENCY_FIX_REPORT.md"
    contents:
      - "Problem: Asyncio false parallelism"
      - "Diagnostic evidence"
      - "Threading implementation"
      - "Verification results"
      - "Before/after comparison"

  - file: "baseline_threading_VALID.json"
    description: "NEW valid baseline with true parallelism"

  - file: ".checkpoints/phase_3_REVALIDATED.json"
    description: "Phase 3 results with threading (replaces invalid asyncio results)"

# ============================================================================
# REFERENCES
# ============================================================================
references:
  issue: "False parallelism - 24 bots claimed but only 6 cores active"
  root_cause: "Asyncio cooperative multitasking, not true concurrency"
  solution: "Threading with Z8 heartbeat pattern"
  evidence: "CPU history screenshot, 100% success rate suspicious"
  fix_date: "2025-10-22"
